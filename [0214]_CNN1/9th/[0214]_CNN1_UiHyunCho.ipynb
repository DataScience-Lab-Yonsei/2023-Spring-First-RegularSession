{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdNvme8aKSBP"
   },
   "source": [
    "# 초기 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P1v9luAfHXdz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D39aCPyTu2Ce",
    "outputId": "6556b065-c4c1-4840-95a5-a830ef48b3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02LdHlTTSz5L"
   },
   "source": [
    "- 현재 GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ybsjn80uSx3X",
    "outputId": "7c7f0037-644d-4a22-b8ac-e6aa3c23717d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colab의 runtime-type을 GPU로 설정해서, True가 나오도록 한다.\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlPZI5wfDQhv",
    "outputId": "7d1caa49-8789-4006-d30c-8dd67003e7b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHckdZ55KeH2"
   },
   "source": [
    "# FashionMNIST 분류 모델 만들기\n",
    "* 흑/백(1) 이미지 데이터 분류\n",
    "* 28x28 pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCrBa-gRRMEO"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vYP9dGrWzDqd"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "MNIST_transform = transforms.Compose([transforms.ToTensor(), # tensor로 펴준다.\n",
    "                                      transforms.Normalize((0.5,), (0.5,))]) # 정규화를 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VpVsTevTWE5i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3331550055f4bd58babfbda2af190c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to /content\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46280d27cc384191af54fce61213ad28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to /content\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3a2050bc3d4f1d91f5147a2c7f6088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to /content\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d931cb51b7e14ca8aa8bcb9e54be9e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to /content\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.FashionMNIST(root = '/content',\n",
    "                                 train = True, download = True,\n",
    "                                 transform = MNIST_transform)\n",
    "\n",
    "testset = datasets.FashionMNIST(root = '/content',\n",
    "                                 train = False, download = True,\n",
    "                                 transform = MNIST_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qh7uI7ewsipv"
   },
   "source": [
    "input-data size 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Dz-CJf0x0nne"
   },
   "outputs": [],
   "source": [
    "# batch-size=128\n",
    "train_loader128 =  DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 2)\n",
    "test_loader128 =  DataLoader(testset, batch_size = 128, shuffle = False, num_workers = 2)\n",
    "\n",
    "# batch-size=64\n",
    "train_loader64 =  DataLoader(trainset, batch_size = 64, shuffle = True, num_workers = 2)\n",
    "test_loader64 =  DataLoader(testset, batch_size = 64, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy6D1Rg_07fD",
    "outputId": "b484c480-d51e-406e-8419-a47f44c4c75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 128 : batch-size\n",
    "# 1 : 흑백\n",
    "# 28x28 : pixel-size\n",
    "\n",
    "images128, labels128 = next(iter(train_loader128))\n",
    "images128.shape, labels128.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AotS6123m9sK",
    "outputId": "9d7eb726-4551-4c9c-bf85-ff4a907e5922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64 : batch-size\n",
    "# 1 : 흑백\n",
    "# 28x28 : pixel-size\n",
    "\n",
    "images64, labels64 = next(iter(train_loader64))\n",
    "images64.shape, labels64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g4Nd4uLGTEDy"
   },
   "outputs": [],
   "source": [
    "# 숫자 label에 해당되는 값\n",
    "\n",
    "labels_map = {\n",
    "    0: 'T-Shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "_u5_UEAH09SB",
    "outputId": "5267a478-beeb-40d7-f0ac-ce77e7c28c7b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACsCAYAAACelPbNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApeUlEQVR4nO3deXBVVbrG4S+GDGTAEESQQUAggCAg2NooKCgKKiq0YuOMYyuKA6XiRKlIiQPOCiqllvPYDiVO7QROoCii2IIoAgIhIRAJmcd9//CSEta77ZUdSEjye6pulb599l77nKy9zlme+30nJgiCwAAAAAAANbJbfV8AAAAAADREbKYAAAAAIAI2UwAAAAAQAZspAAAAAIiAzRQAAAAARMBmCgAAAAAiaFbfF1CXpk2bZgsXLjQzsxUrVlj79u0tMTHRzMxefPHF6n8GGprKykp76qmn7M0337TKykorLy+3YcOG2WWXXWbx8fE1Pl9+fr5dfPHF9tRTT+2Eq0VTUZM1d/bs2TZnzhwLgsCqqqpsyJAhdsUVV1h8fLxdc8011r17dzv33HOdMU444QR7+umnrUWLFtvkzGH4Wrx4sd111122efNmC4LA2rZta5MnT7bu3bvv0HG+/PJLu+WWW2zOnDk79LzAVmvXrrUjjzzSMjIyzMysqqrKkpOT7cwzz7Rjjjmmnq+u8WpSm6kbbrih+p8PP/xwmzFjhu233371eEXAjnHTTTdZXl6ePfnkk5aammpFRUV25ZVX2vXXX2933nlnjc+Xl5dnS5Ys2QlXiqbEd81955137IMPPqjeYJWWltqll15qDz74oE2aNOkvx3jjjTdkzhyGj7KyMvvXv/5ljz/+uPXu3dvM/phT559/vn344YcWGxtbz1cI1ExiYuI26+K6dets/PjxFhsbayNGjKjHK2u8mtRmKswDDzxgixcvtg0bNliPHj1s+vTpdtttt9n8+fMtNjbW+vbta9dee62lpKTY4Ycfbvfdd1/1B4Kt/96rVy+75ZZbbNGiRRYXF2cdOnSw6dOnW3Jysi1atMhmzJhhxcXFtttuu9kll1xiw4YNs1dffdVeeeUVKy4utpSUFHv66afr+ZVAQ7R27Vp788037bPPPrOUlBQzM0tKSrKbb77ZFi1aZPn5+XbzzTfbsmXLLCYmxoYMGWKTJk2yZs2a2SuvvGIvvviilZeXW15enp1//vl26qmn2rXXXmslJSV2wgkn2KuvvsoHCuxUOTk5VllZaSUlJZaYmGgJCQk2ZcoUy83NrX7Mt99+a+PGjbONGzda9+7d7a677rKkpCTr0aOHzZ8/3+bOnbvNempmzGH8T8XFxZafn29FRUXV2fHHH28pKSk2f/58e/DBB61jx472888/W0VFhd188802cOBAKysrsxkzZtjChQutsrLS9t13X7vhhhssJSXFPv74Y3vkkUesrKzMcnNzbfTo0Xb55ZdvM+7XX39tV155pd199902YMAA++ijj2zWrFlWXl5uiYmJNnnyZNt///2dzyczZsyo41cIDV379u3t0ksvtccee8w+/vhj27x5s61Zs8aGDh1ql112Weg8fu655+yFF16wuLg4S0hIsKlTp1q3bt1C8yYtaKKGDRsWfP/990EQBMH9998fjBgxIigvLw+CIAjuu+++4JJLLgnKysqCysrK4JprrgmmTJniHPfnf1+4cGEwcuTIoKqqKgiCILjjjjuCb775Jti8eXNw1FFHBWvWrAmCIAiysrKCQw89NFi3bl3w73//O/jb3/4W5Ofn1+VTRyPz7rvvBieeeGLo/3711VcHt9xyS1BVVRWUlpYG55xzTvDII48EBQUFwcknnxzk5uYGQRAE3377bdC/f/8gCIJgzZo11f8M7Ajbr51/tmXLluDss88OevfuHZx88snB9OnTg6+++qr6f588eXJw0kknBUVFRUFFRUUwZsyY4LXXXguCIAgyMjKCTZs2Oespcxi+Hn/88aBv377B4YcfHlx55ZXByy+/HBQVFQULFiwIevXqFfz4449BEATBY489Fpx22mlBEATBAw88ENx2223V7/l33XVXcOONNwZVVVXB6aefHqxcuTIIgj/e83v16hVs2rQpWLBgQXDssccG8+fPD4YPHx4sXbo0CIIgWLlyZTBq1KjqtXj58uXBIYccEhQWFjqfT4C/ErbuLV++POjXr18wefLk4KyzzqrOw+ZxRUVF0Lt37yA7OzsIgiB47bXXghdeeCE0b+r4Zur/9e/f35o1++Pl+OSTT+yKK66wuLg4MzM744wz7OKLL/7L4zMyMiw2NtbGjh1rgwcPthEjRljfvn1t3rx5lpOTs83xMTEx9tNPP5mZWY8ePar/KyoQxW677WZVVVWh//snn3xizz//vMXExFh8fLyNGzfOnnzySbvgggvs4Ycftnnz5tmqVats2bJl2/zXWaCupKam2uOPP25r1qyxBQsW2FdffWUXXHCBnXrqqXbVVVeZmdnw4cOtefPmZmbWvXv3bb612or1FFGcffbZNnbsWFu4cKEtXLjQZs+ebbNnz7arrrrK2rVrZ7169TIzs3333ddee+01MzObO3eu5efn2xdffGFmZuXl5daqVSuLiYmxhx9+2ObOnWtz5syxFStWWBAEVlxcbGZmWVlZduGFF9opp5xiPXv2NDOzzz//3DZs2GDjx4+vvqaYmBj77bffzGzbzydAFDExMdU1qgMHDqzOw+ZxbGysjRw50saNG2dDhw61wYMH22GHHRaaN3Xcnf8vKSmp+p+rqqosJiZmm38vLy+v/vcgCKr/uayszMzMWrRoYW+88YYtWrTIFixYYJdffrmde+65ttdee1nXrl3t5Zdfrj4mOzvb0tPT7c0339xmXCCKvn372q+//moFBQXbfJDMzs62KVOmyPlcUVFhWVlZ9s9//tNOPvlkGzhwoI0cOdI+/vjj+ngKaGJOOOGE6n+eNm2aLViwwAYOHGgDBgywjh072tixY+3rr7+2888/v3oz9ecPkzExMdusw1uxnqKmvvnmG/v222/tvPPOs2HDhtmwYcNs0qRJNmrUKKuoqNimScqf511VVZVdd9111R8kCwsLrbS01IqKimzMmDE2fPhwO+CAA+zEE0+0Dz74oPq42NhYe/TRR23ChAk2cuRI69evn1VVVdmgQYPs3nvvrR5r/fr1tueee9r777/PvEatLVmypLopxfafd9U8NjObMWOGLV++3L744gt79NFH7Y033rD77rsvNG/KaI0uDBkyxJ5//nkrLy+3qqoqe/bZZ+2QQw4xM7P09HT74YcfzOyPzjw5OTlmZvbxxx/b+PHjbf/997eJEyfa6NGj7YcffrD+/fvb6tWrqztaLV261EaMGGHZ2dn18+TQ6LRp08aOO+44u+6666ygoMDMzAoKCuymm26ytLQ0Gzx4sD3zzDMWBIGVlZXZSy+9ZAcffLD98MMPlp6ebhMmTLDBgwdXb6QqKyutWbNmVllZKT+wArX1xhtvVP/ffvvtZyUlJdXd1LZavny57bvvvpHHYA7DR3p6us2aNcu+/vrr6iwnJ8cKCgq2mY/bGzx4sD377LNWVlZmVVVVNmXKFLv77rtt9erVVlBQYJdffrkdfvjh9uWXX1Y/xsysdevWNmDAAJs8ebJdffXVVlxcbIMGDbLPP//cVqxYYWZm8+bNs+OPP95KSkp26nNH07By5UqbOXOmnXPOOc7/FjaPc3Nz7bDDDrO0tDQbP368XX755bZkyZLQvKnjmynhoosusttvv91Gjx5tFRUV1rdvX5syZYqZmV155ZV200032Ysvvmi9e/eu7v5z6KGH2ieffGKjRo2ypKQk23333e2WW26x9PR0u//+++2OO+6w0tJSC4LA7rjjDuvQoYN99dVX9fk00YjceOONNnPmTBs3bpzFxsZaWVmZDR8+3CZOnGiFhYU2bdo0O+6446y8vNyGDBliF154oVVWVtorr7xiI0eOtJiYGDvwwAMtPT3dVq9ebZ06dbK+ffvasccea88++6y1bNmyvp8iGrEJEyZYTEyMjRs3zmJiYqyqqsr69OmzzX+pr6nWrVszh/E/denSxR566CG75557LCsryxISEiw1NdVuvfVWS0hICD1uwoQJdvvtt9uYMWOssrLSevXqZddcc40lJSXZ0KFD7eijj7b4+HjLyMiwbt262erVq7f5mYoxY8bYe++9Z7fddpvdfPPNNnXqVJs0aZIFQWDNmjWzWbNmWXJycl28BGhktjbeMfujDCAhIcEmTZpkQ4cOtXfffXebx4bN45SUFLvooots/PjxlpiYaLGxsTZt2jRLT0+XeVMXE/Cf7QAAAACgxvh/8wMAAACACNhMAQAAAEAEbKYAAAAAIAI2UwAAAAAQwV928/vzb9M0NP369XMy1WZ3a8vyP9v643p/1rZtWyfb2i59e/vss4+Tvfnmm062227uXvb999+X52yo6rq/SUOes8qAAQOc7M+/0bOVmrNbfyviz7b+zsT2/txlaqsff/zRyTZu3OhkW9v5/tlnn30mx2kI6qMnj++8VWuGmf3ljzb/r3HUj4FWVlZGHiPM9ddf72Tt2rVzsjVr1jhZ2Ouj5n1hYaGT9ejRw8luvfVWJ1M/BFwT6jrraj6x1qKhYc7WTufOnZ3szDPPdLJXX33Vybb+xI+P1NRUJ5swYYKTfffdd062fffAhi5szvLNFAAAAABEwGYKAAAAACJgMwUAAAAAEbCZAgAAAIAIYoK/qABsyMV6r7/+upMddNBBTrZ06VInUwXZrVu3drIOHTrIsVNSUpxs+fLlTlZWVuZkt99+u5M988wzcpyGgAJTf6og/rDDDnMyVUzfqlUrJ5s3b56TqcYsZmZpaWlO9vvvvzuZmrOqCcB7770nx7nwwgtlvr2mVMhvtnMaUMTGxjqZaizhKzk5WeZXXHGFk51++ulOFhcX52Rq3qrHJSUl+VyimemGKKqAWq3zb7/9tjzngw8+6GRffvml9zXVBdZaNDSNdc6qddq3gc+NN94o8zPOOMPJ1q9f72QJCQlOpj6/qmZS6r3czKxLly5O9ssvvziZWlP33HNPJ/vpp5/kOLNnz3Yy1bytPtGAAgAAAAB2IDZTAAAAABABmykAAAAAiIDNFAAAAABE0GgbUJSUlDhZfn6+k6mC7BYtWng9Ljc3V46tivQTExO9MlU0np6eLsdpCBprgamiii8rKiqcLKyQf9myZU62YcMGJ5szZ46THXDAAV7Z4sWL5diq6F/dB6pAVc33QYMGyXHGjx/vZC+99JKT1aaAt7Z25QYUYWrTbGLw4MFOdsMNNzhZ+/bt5fHNmzd3sqKiIicrLCx0MvV3VpmaY2Z6bSwtLfXK1P2qmgeZ6fvj559/drKPPvrIyVRToZ2hKa21aBya+px96KGHnOyYY46Rj129erWTqfdjta6p9wKVqTXaTDeRyMnJcTLVKEi95uqzr5lu6jZ9+nQne+KJJ+TxdYEGFAAAAACwA7GZAgAAAIAI2EwBAAAAQARspgAAAAAgAjZTAAAAABBBo+3mV15e7mS//fabk6kOYaqblOqQojpWmelOJep41aFKdcxq06aNHCcvL0/mu5LG2q3HtwuZ6uZ34IEHynOqzj6q486sWbOcbODAgU6mOuf9+uuvcuzMzEwn69Gjh5OpDj5r1651sn79+slxCgoKnGz//feXj60vu3I3v7DH+V7z3LlznWyfffZxMtUNNazTkxpbdb9Ta61aK1WHKnVvmen7Sz1WvW4JCQlOpp63mb521cVQdQNctWqVk40YMcLJwt5P1LWr17yxrrVovBrDnPXtPDtgwAAnu++++5wsbA1Sr5XqUN2pUycn8+3CG9YBVq2VqkOqen3V81Gdgs30+4F6LYcMGeJk6r1gZ6CbHwAAAADsQGymAAAAACACNlMAAAAAEAGbKQAAAACIwO2K0MD0799f5qrhgyrWU4V1vs0FVJG1mS5QU8V6qkmG0qtXL5kvWLDA63jseKooUmXKqFGjZL7ffvs52cKFC53s2GOPdbKxY8c6mWoMoeahmVnv3r2dbP369U6mCkfbtWvnZGHF9Js2bZI5/NSkYPvaa691soyMDCdbt26dk8XHxzuZWlPDqOtUa6gqgg5bV5XaFJSr9Tc2NlY+Vl2TOj4rK8vJOnfu7GQzZ850MtUwxqx+GqIA8OP7vv/YY485mXo/DltnVXMb1bBMfaYNa/iwvdDmCmLtVo9Vr4VqfhFm8+bNTqbeiy655BInu/fee73H2Rn4ZgoAAAAAImAzBQAAAAARsJkCAAAAgAjYTAEAAABABA2+AYX6JeTa8i2eDisUVIXJqiBfPU4VVA8aNEiOQwOK+qP+Tmre9OnTx8nOO+88ec5vvvnGa+wjjjjCydRcSEtLczLVhMXMbI899nAyVci6ZMkSJ1P3gSqMNTPr16+fk1100UVONmvWLCfz/aV5/GHEiBFOtnHjRidTTRdq09jBTP9d1DlVVtu/qboPfdf0sAYUFRUVXo9VxdK5ublO1r17dzkOgIbv6KOPdjLVfEl9BlQNa8z0eqPWJfUer45Va2LYuu/7fqAa9ajPB0lJSfJ41axCNaU47bTTnIwGFAAAAADQALGZAgAAAIAI2EwBAAAAQARspgAAAAAgggbfgOLII4+U+ZYtW5zMtwDat1gvjCps9h1nw4YNTnbooYfKce655x7va8KO5Tsfpk+f7mRhvwiuGkakp6c72U8//eR1PaqBxD777CPHVnO2Y8eOTta1a1cnUwWva9askeNkZWU5mfo1c9WAgmYT4YYOHepkbdu2dTLVCMe3sDmsOUNt+BZBh41dWVnpdbwaRxV/16QBhRrbt9FFq1atnEw1ZzEz++6772QOYNd0yimnOFlpaamT+TZ+MjPLy8tzMt/Pmr6NftT5zPyb+qjPNupxYc3b1DqrmlWotbddu3ZOlpmZKcfZGfhmCgAAAAAiYDMFAAAAABGwmQIAAACACNhMAQAAAEAEDb4BRZs2bWSufnU+MTHR65yqMDk5OdnJwoqVf//9dyeLj493spKSEidTv/ackpIix8Gur2fPnk6miifDcjXHunXr5mTNmzd3MlXImp2dLcdW8041cVH3hsrKysrkOOqawh4LfxMnTox8rCrwVY0qwhqAhBUtb8+3MYTKwu4ZX76F2mHjqIJp9Vi1VhcWFjqZuq9PPvlkOTYNKHZ9NWlaVZtGOq+++qqTvf/++/KxqomPou4Nmv34u/POO50sIyPDydQ6oJpShK1B6u+kPleqeafmp3rfDVvL1fqnHuu7dofNL99rV5/Hr7/+eie7+OKL5Tg7A99MAQAAAEAEbKYAAAAAIAI2UwAAAAAQAZspAAAAAIigwTegCGsqoQrda/OL9apZhCqCMzNLT093spycHK+x1S9ir1q1So6DXV9+fr6TqWYRZrogfuXKlU6m5rYaR90bNSkwVY0lVBGt+tXyFi1ayHHU+KmpqU6mmmz88ssv8pww69Spk5MVFBQ4mfo7x8XFeWXqfGGPVUXDvg0olLCCZXVOlanj1ePCqEJxRd3b6tji4mInO+OMM+Q5VWE16o9v4xLVHMBMF/4PHz7cyW677TYn++GHH5zsggsukOOozyxPPPGEk9Wm2UTXrl1lrub82rVrI4+zK3vttdecbNSoUU7WsmVLJ1u/fr2Tha2Jvk10fDP1XlCTNVG976vPJuq6VSMVM30fqM/ZGzZscLKZM2fKc9YVvpkCAAAAgAjYTAEAAABABGymAAAAACACNlMAAAAAEAGbKQAAAACIoMF388vMzJT53nvv7WRr1qxxMtUF7YADDnCy119/3clUFyszs1NPPdXJ1HWqLjq77767k3322WdyHOxaVAe6tLQ0JwvrntS5c2cnUx3sNm/e7GSqY47qqBY2tu/xqoOPug/UczEzy8rKcjLVAahPnz5ORjc/sylTpsi8Q4cOTqY6Qfr+TVUnMtWxLOycvp2nwrpL7mhqHJWFPUeVq46VqgOmen1VZ8Swe3Pw4MFOxntC/fHtAKy69oU57rjjnEzdv61bt3ay1atXy3OedNJJTnbIIYc42cSJE51MdZtUHnvsMZmr12jYsGFe52xovvjiCyf7+9//7mTPPfeck6nuzWq9MPPvUO27zqpxarseq/WvVatWTjZr1ix5vLoPnnrqKSebOnVqhKvbufhmCgAAAAAiYDMFAAAAABGwmQIAAACACNhMAQAAAEAEDb4BhSr+MzM76KCDnEwV67Vs2dLJVBOIuXPnOllGRobHFf5BNbpQhduq8PvTTz/1Hgf1RxWTqrm0adMmebwqMFUNLNTjSkpKnEwVtKsC0TBqnOTkZCdLSkpysrDn6Nvo4ogjjnAy1QSmqXn++edlrpqfDBo0yMmaNXOXfDUn1FxWTRPMdCGzb2G0oh6nCtprck51fE3uDzVvU1JSnKy0tNTJ1Pxu06aNk6l72MxsyJAhTkYDil1LWPMQZcyYMU6mGkuoZj0qO/jgg+U4aq0eOHCgk2VnZztZTk6Ok6kmWmqdMAtfp5qKvLw8Jzv22GO9jv31119l7rsuqsx33Q/j25hC3QeqAUVYM6mafKbe1fDNFAAAAABEwGYKAAAAACJgMwUAAAAAEbCZAgAAAIAIGnwDig8//FDm6heSa1JUvb333nsv8rFmulhZFQWqAuawJhvYtXTp0sXJVEMRVRhsZrZ48WInS01NdTJV0K4K/pWaFEqrAlVVBFtWVuZknTt3ludct26dk6ni1v79+//vC2yCwgp3zzrrLCcbMGCAk02fPt3JjjrqKCf7z3/+42RhxeZqHVPzTGW+xdJhBdC+jSV8C6jDGl3stddeTnb33Xd7ZapZxFtvveVk06ZNk2MXFhbKHLu2sWPHynz27NlOpu7r9u3bO9mXX37pZM2bN5fjxMXFOZlqKrRy5Uon8224EtY0RY3dlKjXz/e9VzWtMjPbsmWL1/HqPVp9ZvA99q/y7annqJqmHHroofL4Tz75xMnUZyj12SRs7a4rfDMFAAAAABGwmQIAAACACNhMAQAAAEAEbKYAAAAAIIIG34BCFU+GWb9+vZOFFW/6HPv77797j62K9FWhIcXGDVfXrl2drKKiwslUEbCZWcuWLZ1MNZZQc0SNo4pOExMT5djqseqcah6rhgHqWDOzpKQkJ1PFymFNOuBv0aJFTjZixAgn69mzp5MtW7bMyRYuXCjHUX+rsML07e2MouHaNKBQ89vMrF27dk720EMPOdk999zjNQ7qRljhvW/DHl8vvfSSk6mGDWZm8+bNc7K1a9c6WXp6upOpxj45OTlyHHVf+j5vtabn5uY6WVizhI4dO3qN01jVZl3LzMyUeVpampOp91m1/vk29QlrNKEeq+aSGlvdgwMHDpTjqAYUvo2L6hvfTAEAAABABGymAAAAACACNlMAAAAAEAGbKQAAAACIoME3oFCNIcx08bUqmPNtQKGoX2EOc9FFFznZ+++/72SrV6+OfD2oX3vttZeTqUL8sMLkVq1aOdnSpUu9zqmaWqgizdLSUjm2+pVxVbTq24AirNBZFdGqhhphhc1NXU0K6tVj1eNUs4maUOugb9GwukZ1bFhhtMpVpgq11bwNaw6jjq/J+u8j7Dkqu2IB9q6oto0m1Pv28ccf72Rbtmxxsp9++kme87jjjnMy9bfv1KmT1zhhc7a4uNjJNm3a5GR77rmn1/UUFRU5WVhDox49esi8qajN/anWPzP/JjpqbHVsbRtQqMf6XmPYZ6CGjG+mAAAAACACNlMAAAAAEAGbKQAAAACIgM0UAAAAAETQ4BtQhGnbtq2TqUJL9avevmpSMDxx4kQnU8WgP//8c+TrQf1q3769k6lmEWFNTxYvXuxkSUlJTqYKTFWmioPDCmNVMb0qJlXnVMX5eXl5cpwuXbo4WUFBgZOpAtUWLVo4mSrIbszCCup9GznURmZmpsy7devmZGptVNeumkD4zm8zs7i4OK9xfIWt6TW5pu2p56jumTANvdlETZqH7Og527FjR5mr9+Ojjz7ayXJycpxsyZIlTpaRkeFkqllP2PGq4Y5qDKPeD1RTnzAtW7Z0MnUPqWyPPfZwsrC5qd4LmxI1t33v47DH+X7e9G0MUZPPr7581301l8Ls6DVhZ+GbKQAAAACIgM0UAAAAAETAZgoAAAAAImAzBQAAAAARsJkCAAAAgAgabTe/FStWOJnqIKI6iflSnXXC9O7d28mSk5OdbN26dZGvB/UrISHByVTXrtLSUnn8O++842RnnHGG1/G+XXRUVx8z3UFIdR0sKipyMtXhb82aNXKczp07e12Tuh7Vmeu///2vHKepqU0HO1+FhYUyV38/1YFJ/U3VseqeCZu3vp2efK8n7HzLly93MnV/FBcXO5nv36ahde1THSRVFtbVrjbP97zzznOy448/3snC1lrl9ddfd7KBAwc6mepIqsZRr4WZ2dq1a51MraF77bWX1znVnDMzi4+PdzLVXVZR95s6X9jfUK3VPXv29Bq7qQtbg3zfJ33XWd/z1eR43w6d6enpchyFbn4AAAAA0IixmQIAAACACNhMAQAAAEAEbKYAAAAAIIJG24AiOzvbyXbffXcnq4vCbTOzzMxMJ+vQoYOTzZ8/vy4uBzuBKkhXhcWqUYWZ2ZYtW7zOmZOT43VOVazcrJm+5dV9oK5dPS41NdXJfvzxRznO0qVLnaxNmzZOlp+f72SqgQzqTlgjAd/mJ76F0ep8Kgs7p28RdE2oc4bdS9tTz7Gu3nd2JvUcdsbz6tSpk5NdcsklTvbdd985WViDKbWW9OnTx8lWrVrlZFlZWU6mmlH16NFDjj1o0CAn822EpZqzhDUNUOu3alahjleNKtTYYQ0t1HvZ6NGj5WOxLd91xcx/XVPrl/p8EHb/quN9197y8nInU42oGjq+mQIAAACACNhMAQAAAEAEbKYAAAAAIAI2UwAAAAAQQaNtQKGK9Pfdd18n8y2sU37//Xfv61HnVAWdqnATDUOrVq2cTBV5btq0SR7funVrJ1MFpmreqCJ39biwQn7V6KKoqMjrekpLS52sbdu2chw1v7t16+ZkqgGFaiCDuqOK7HeGsDm6o8+pMnUfhVH3tu/YjcHgwYOd7B//+IeTqfdiMz2fUlJSnEytY2+99ZaTtWjRwsnUGmZmlpeX52SqkU5ubq6TqSL9Pffc08nC7hfVbMJ3jqi1NmzO+jYD2bhxo5PFxcV5j6P8/PPPThb2ntAY1eZzZU2apqi/sW9TH/U3rkmjHt/nqLKaNNloKPhmCgAAAAAiYDMFAAAAABGwmQIAAACACNhMAQAAAEAEja8K7P8VFhY6WXx8vJOpQndVnKqoX0IPowpH1TWq60HDkJyc7GSqSDOsyDMjI8PJVMMGVWCqiuHV48LGLisrczJVQK0KR9XcTktLk+OoYnI1tiqObd++vTwn6kZCQsIOP6dvY4iw4m3fwn3fwmjfInEz/X7SlKi1adWqVU6m1sUwqqBeNezp2bOnk/k25jHzbxjRoUMHJ8vMzHQytf7WpPGIWu9UlpiY6GRh81A9d7V+q+tU97rK1GtuppsFderUST62MapN05mw+6W8vNzJ1Pu5b6MQNb/UGGHnrElDku2p9/yGjm+mAAAAACACNlMAAAAAEAGbKQAAAACIgM0UAAAAAETQaBtQqAJ4VaipfnFd/SK44vu4sLFV1qZNG+9zYteiCjp9G0OY6TmrCkLVOVUhqnqcysx04b0qolVzVl1j2HNURcyqwFzdl126dJHnRN0Ia16i+M4nNU98j/2r3OdxYcXWinruYcX3TcWPP/7oZN9//32tzqmaFHTu3NnJcnNznUw1PWjVqpUcRzV6Us0Z2rVr52StW7eW59yeahZhpudiSUmJ1/Wo9Vc17TAzKyoqcrKCggKv4zdv3uxkGzZscLL169fLsdW99emnnzrZ6NGj5fFNWW0b/ag1Vf091DhqHtZkHF87o5lRfeObKQAAAACIgM0UAAAAAETAZgoAAAAAImAzBQAAAAARsJkCAAAAgAgabTc/1WkpOTnZyTp06OBk69at8xpDdcYJ07FjRydr3ry5k6lOVmgYkpKSnEz9PX/77Td5vJqfah6rLjq+WVhHNpWrrlOqY1ZOTo6TlZWVyXH22GMPmW+vtLTUydq2bet1LHYO9Tcx03NcZWo+hnWX3F5Y1z51TnXPqHFq0jVQ3R9hr0dToda79PR0Jwtbc9Trl52d7WSrV692snnz5vlcIrBLU58BVWamuy76dtTzXY9Vt8iwsX0/q6r7P2wcX2qdru/PznwzBQAAAAARsJkCAAAAgAjYTAEAAABABGymAAAAACCCRtuAYu3atU6WkJDgZC1atHCyFStW7PDrUcXzzZq5L//GjRt3+NioG+rvWVxc7GR9+vSRx2dmZjqZKt70LfgPK/xWfAtU1XNUx6qCVTN9v8XFxTmZagLTunVreU7UjfLy8lodH9bcIerjanK8ytRcDpu3YXlTtmXLFq8sjPqbqCY8qulNamqqk6m/Z1iBvlobfddL9Ti1ztekIF69FqqRipqHYfeL732gXiPfx6nXPOz4zZs3y8c2ZaqJS9icVU2dfNdKNRdVU56whkA1+Szhc6z6LN7Q8c0UAAAAAETAZgoAAAAAImAzBQAAAAARsJkCAAAAgAgabQOK3NxcJ1PFdaqAr7aF1ooquFNFgapxBhoG3yJPVVhs5l/krop+fYuNw8ZW81MVeWdlZTmZKpgNey5qfPWL76rYVjWqQN0JK6j3nXu1OTasKNv3eHXtap0Pu+6w8RGd+psUFBR4HZuXl7ejLweoczVZV1Qjh9qsdUpYQxH1fuzbtEo9Tr3nN3S8QwAAAABABGymAAAAACACNlMAAAAAEAGbKQAAAACIoNE2oPD99XDVIGDTpk07/HpUYZ7vNWLXk5aW5mSqOYN6XFFRkTxnbYrca/Mr9ma6wFRlvvdQSUmJHEcV0arHqoLZ5ORkeU7UDfW3M/Oft74NgNT5wsZW51RUYbWad2HnU7lq2lJYWOh1PQBQk2Znag1UnyGTkpK8zqfWxLAmT2qc0tJSJ1PNJtR1h63nDRnfTAEAAABABGymAAAAACACNlMAAAAAEAGbKQAAAACIoNE2oPAtVlcFc7UtIlbFeqrQ2vfXq7HrSU9PdzJVOK8aNoQVX6qGD4mJiU7mW+SphDULUHlxcbGTqQJVVYgf1oBCvR6qELZNmzZOVlBQIM+JuqHWNTP/+aiaOPjOWzVHzPQaqqixa1L8re6PsGLt7fleI4CmZfPmzU6Wn58vH6saS/iuveqzRU5OjpM1b95cjq3et+Pj4yM/bsmSJXKchoxvpgAAAAAgAjZTAAAAABABmykAAAAAiIDNFAAAAABE0GgbUKjieVWsp7Ls7OxajZ2VleVkqkhfja0eh13Pr7/+6mSqWUTLli2dTBWDmulCTd8CU9UcQBXthxXDq3HUY4uKipxMPR9V8G+mn6N6bKdOnZzsmmuukedE3QhrzKOKjtV8VJlap9V8CmtAoahxfJvDhDWlUOP7Ns8A0LTUppHYli1bZJ6amupkqoFFZmamk5WWljqZWtO6dOkix/7ll1+cTL2XqyYZe+yxh5Op51ITu2KjNr6ZAgAAAIAI2EwBAAAAQARspgAAAAAgAjZTAAAAABABmykAAAAAiKDRdvNLS0tzMtVBRHWOysjIqNXYHTp0cLKSkhKvY1X3NzQMe++9t9fjPv30U5kfdNBBTqY6k9Wm42NYBzLVuS+s89/21D0U1hUtJSXFyW666SYnmzp1qtfYqDuqI56ZXldV9yi1rqpzqmPDxladINUcV8evX7/eydT9ZqbvueTkZCfLycmRxwNoOmrTbS4vL0/mqtOeWoN69OjhZGHr2vZatWolc7Wmqs+0GzdudDK1nquuwA0d30wBAAAAQARspgAAAAAgAjZTAAAAABABmykAAAAAiKDRNqCYO3euk73yyitOpgqT58yZU6uxVfH8fvvt52RbtmxxsuXLl9dqbOz6hgwZ4v3Y+Ph4J1ONLoYPH+5kqplJYWGhHEcVnqoC08rKSid7++23nWzVqlVynIKCAplj1/fAAw/IfNmyZU6mGo2oeRsXF+dkYc0mFDWfVQG3KgjPz893shUrVshxVKF32BzfnrpnADRetWlA8dVXX3mfMzMz08lq0zgqrAGaGlsdr9ZutUar5j8NHd9MAQAAAEAEbKYAAAAAIAI2UwAAAAAQAZspAAAAAIggJqhNpRwAAAAANFF8MwUAAAAAEbCZAgAAAIAI2EwBAAAAQARspgAAAAAgAjZTAAAAABABmykAAAAAiOD/AMiDmIX3ETj/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x864 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "figure = plt.figure(figsize=(15,12))\n",
    "cols, rows = 5, 1\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    image = images128[i].squeeze()\n",
    "    label_idx = labels128[i].item() # y_label\n",
    "    label = labels_map[label_idx] # 위에서 해당되는 label\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFPYE3UUnpmX"
   },
   "source": [
    "## 모델 1 생성\n",
    "* 10개의 convolution-layer(Conv2d)와 2개의 fully-connected(fc)로 이루어진 모델\n",
    "* Total params: 28,784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orF-z9choFaB"
   },
   "source": [
    "input-data size\n",
    "* train_loader128(batch-size;128) : 128, 1, 28, 28\n",
    "* train_loader64(batch-size;64) : 64, 1, 28, 28\n",
    "\n",
    "\n",
    "구현해야하는 모델 정보<br>\n",
    "* convolution-layer 1\n",
    "* maxpooling-layer\n",
    "* convolution-layer 2\n",
    "* convolution-layer 3\n",
    "* convolution-layer 4\n",
    "* convolution-layer 5\n",
    "* convolution-layer 6\n",
    "* convolution-layer 7\n",
    "* convolution-layer 8\n",
    "* convolution-layer 9\n",
    "* maxpooling-layer\n",
    "* convolution-layer 10\n",
    "* flatten\n",
    "* fc1\n",
    "* fc2\n",
    "\n",
    "추가 정보\n",
    "* 활성화함수 : relu\n",
    "(단, maxpooling과 마지막 fc2에는 보통적으로 활성화함수를 사용하지 않는다.)\n",
    "* flatten의 경우, weights가 들어가지 않는다. 즉, layer라고는 볼 수 없다.\n",
    "\n",
    "모델의 layer를 통과함에 따라 데이터의 크기 변화는 다음과 같다.\n",
    "1. batch-size128 -> torch.Size([128, 1, 28, 28]) 으로 시작\n",
    "2. batch-size;64 -> torch.Size([64, 1, 28, 28]) 으로 시작\n",
    "> * torch.Size([128 or 64, 5, 30, 30])\n",
    "> * torch.Size([128 or 64, 5, 15, 15])\n",
    "> * torch.Size([128 or 64, 7, 15, 15])\n",
    "> * torch.Size([128 or 64, 16, 16, 16])\n",
    "> * torch.Size([128 or 64, 19, 15, 15])\n",
    "> * torch.Size([128 or 64, 29, 13, 13])\n",
    "> * torch.Size([128 or 64, 29, 14, 14])\n",
    "> * torch.Size([128 or 64, 6, 12, 12])\n",
    "> * torch.Size([128 or 64, 2, 12, 12])\n",
    "> * torch.Size([128 or 64, 10, 7, 7])\n",
    "> * torch.Size([128 or 64, 20, 7, 7])\n",
    "> * torch.Size([128 or 64, 20, 3, 3])\n",
    "> * torch.Size([128 or 64, 180])\n",
    "> * torch.Size([128 or 64, 86])\n",
    "> * torch.Size([128 or 64, 10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EedVZU7Knv0X"
   },
   "outputs": [],
   "source": [
    "class CNN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model1, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 3, stride = 1, padding = 2)\n",
    "        # in-channels = 1 <- 흑/백\n",
    "        # out-channels = 5\n",
    "        # kernel_size / filter-size = 2x2 -> f=3\n",
    "        # stride = 1(default) -> s=1\n",
    "        # padding = 2(default) -> p=2\n",
    "        # input-data pixel size = 28x28 -> n=28\n",
    "        # (n-f+2p)/s + 1 = new n\n",
    "        # (28-3+2x2)/1 + 1 = 30\n",
    "    \n",
    "        # maxpool : n=30 -> 15\n",
    "\n",
    "        self.conv2 = nn.Conv2d(5, 7, 3, padding=1)\n",
    "        # in-channels = 5 <- 이전것의 out-channels\n",
    "        # out-channels = 7\n",
    "        # filter-size = 3x3\n",
    "        # stride = 1(default)\n",
    "        # padding = 1\n",
    "        # (n-f+2p)/s + 1 = new n    \n",
    "        # (15-3+2x1)/1 + 1 = 15\n",
    "\n",
    "        self.conv3 = nn.Conv2d(7, 16, 2, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(16, 19, 2)\n",
    "        self.conv5 = nn.Conv2d(19, 29, 3)\n",
    "        self.conv6 = nn.Conv2d(29, 29, 2, padding = 1)\n",
    "        self.conv7 = nn.Conv2d(29, 6, 3)\n",
    "        self.conv8 = nn.Conv2d(6, 2, 1)\n",
    "        self.conv9 = nn.Conv2d(2, 10, 2, stride = 2, padding = 1)\n",
    "        self.conv10 = nn.Conv2d(10, 20, 1, stride = 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20 * 3 * 3, 86)\n",
    "        self.fc2 = nn.Linear(86, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x)) # num_flat_features : 아래에서 정의\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x): # 처음 dim-size을 제외하고, 모두 곱한 값을 반환해준다.\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model1(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(7, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(16, 19, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv5): Conv2d(19, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv6): Conv2d(29, 29, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv7): Conv2d(29, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv8): Conv2d(6, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv9): Conv2d(2, 10, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "  (conv10): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=180, out_features=86, bias=True)\n",
      "  (fc2): Linear(in_features=86, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "DeepConv_net128 = CNN_Model1().to(device)\n",
    "DeepConv_net64 = CNN_Model1().to(device)\n",
    "\n",
    "print(DeepConv_net128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gBjDmoc7fJh",
    "outputId": "fdd01796-a38d-4704-9ef7-3d2bc8f66e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = images128.to(device)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tflPlTme7h9x",
    "outputId": "65e3bb98-3a03-47c2-c77a-24db16b3f1f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = DeepConv_net128.forward(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 5, 30, 30]              50\n",
      "            Conv2d-2           [128, 7, 15, 15]             322\n",
      "            Conv2d-3          [128, 16, 16, 16]             464\n",
      "            Conv2d-4          [128, 19, 15, 15]           1,235\n",
      "            Conv2d-5          [128, 29, 13, 13]           4,988\n",
      "            Conv2d-6          [128, 29, 14, 14]           3,393\n",
      "            Conv2d-7           [128, 6, 12, 12]           1,572\n",
      "            Conv2d-8           [128, 2, 12, 12]              14\n",
      "            Conv2d-9            [128, 10, 7, 7]              90\n",
      "           Conv2d-10            [128, 20, 7, 7]             220\n",
      "           Linear-11                  [128, 86]          15,566\n",
      "           Linear-12                  [128, 10]             870\n",
      "================================================================\n",
      "Total params: 28,784\n",
      "Trainable params: 28,784\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 27.10\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 27.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(DeepConv_net128, input_size=(1, 28, 28), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcybKk5Nvj4Z",
    "outputId": "d0eb2b05-23fa-48e1-b023-028dd5597948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = images64.to(device)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2PZCHyyvj4a",
    "outputId": "746d21a5-58c3-40a7-c787-12dfd16b0092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = DeepConv_net64.forward(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uh1pmRXcvZP8",
    "outputId": "88eb1ed5-86f4-45c0-b9b6-006054f92b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 5, 30, 30]              50\n",
      "            Conv2d-2            [64, 7, 15, 15]             322\n",
      "            Conv2d-3           [64, 16, 16, 16]             464\n",
      "            Conv2d-4           [64, 19, 15, 15]           1,235\n",
      "            Conv2d-5           [64, 29, 13, 13]           4,988\n",
      "            Conv2d-6           [64, 29, 14, 14]           3,393\n",
      "            Conv2d-7            [64, 6, 12, 12]           1,572\n",
      "            Conv2d-8            [64, 2, 12, 12]              14\n",
      "            Conv2d-9             [64, 10, 7, 7]              90\n",
      "           Conv2d-10             [64, 20, 7, 7]             220\n",
      "           Linear-11                   [64, 86]          15,566\n",
      "           Linear-12                   [64, 10]             870\n",
      "================================================================\n",
      "Total params: 28,784\n",
      "Trainable params: 28,784\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 13.55\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 13.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(DeepConv_net64, input_size=(1, 28, 28), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVxKI_rwCvhI"
   },
   "source": [
    "## 모델 2 생성\n",
    "* 2개의 convolution-layer(Conv2d)와 5개의 fully-connected(fc)로 이루어진 모델\n",
    "* Total params: 9,516,488"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN5s0Re-CvhI"
   },
   "source": [
    "input-data size\n",
    "* train_loader128(batch-size;128) : 128, 1, 28, 28\n",
    "* train_loader64(batch-size;64) : 64, 1, 28, 28\n",
    "\n",
    "\n",
    "구현해야하는 모델 정보<br>\n",
    "* convolution-layer 1\n",
    "* maxpooling-layer\n",
    "* convolution-layer 2\n",
    "* flatten\n",
    "* fc1\n",
    "* fc2\n",
    "* fc3\n",
    "* fc4\n",
    "* fc5\n",
    "\n",
    "추가 정보\n",
    "* 활성화함수 : relu\n",
    "(단, maxpooling과 마지막 fc5에는 보통적으로 활성화함수를 사용하지 않는다.)\n",
    "* flatten의 경우, weights가 들어가지 않는다. 즉, layer라고는 볼 수 없다.\n",
    "\n",
    "모델의 layer를 통과함에 따라 데이터의 크기 변화는 다음과 같다.\n",
    "\n",
    "1. batch-size128 -> torch.Size([128, 1, 28, 28]) 으로 시작\n",
    "2. batch-size;64 -> torch.Size([64, 1, 28, 28]) 으로 시작\n",
    "> * torch.Size([128 or 64, 5, 30, 30])\n",
    "> * torch.Size([128 or 64, 5, 15, 15])\n",
    "> * torch.Size([128 or 64, 7, 15, 15])\n",
    "> * torch.Size([128 or 64, 1575])\n",
    "> * torch.Size([128 or 64, 3000])\n",
    "> * torch.Size([128 or 64, 1500])\n",
    "> * torch.Size([128 or 64, 180])\n",
    "> * torch.Size([128 or 64, 86])\n",
    "> * torch.Size([128 or 64, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JfSM-k0DCvhI"
   },
   "outputs": [],
   "source": [
    "class CNN_Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model2, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(5, 7, 3, padding=1)\n",
    "        # (15 - 3 + 2 * 1)/1 + 1 = 15\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 15 * 15, 3000)\n",
    "        self.fc2 = nn.Linear(3000, 1500)\n",
    "        self.fc3 = nn.Linear(1500, 180)\n",
    "        self.fc4 = nn.Linear(180, 86)\n",
    "        self.fc5 = nn.Linear(86, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x): # 처음 dim-size을 제외하고, 모두 곱한 값을 반환해준다.\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model2(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=1575, out_features=3000, bias=True)\n",
      "  (fc2): Linear(in_features=3000, out_features=1500, bias=True)\n",
      "  (fc3): Linear(in_features=1500, out_features=180, bias=True)\n",
      "  (fc4): Linear(in_features=180, out_features=86, bias=True)\n",
      "  (fc5): Linear(in_features=86, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "DeepFC_net128 = CNN_Model2().to(device)\n",
    "DeepFC_net64 = CNN_Model2().to(device)\n",
    "\n",
    "print(DeepFC_net128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9IVOG3pwgoS",
    "outputId": "29e66169-48ed-45bc-88b7-f02dbf879c89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = images128.to(device)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4ydm5qCwgoT",
    "outputId": "a292ddaa-eaa9-4408-cd65-2234948598fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = DeepFC_net128.forward(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 5, 30, 30]              50\n",
      "            Conv2d-2           [128, 7, 15, 15]             322\n",
      "            Linear-3                [128, 3000]       4,728,000\n",
      "            Linear-4                [128, 1500]       4,501,500\n",
      "            Linear-5                 [128, 180]         270,180\n",
      "            Linear-6                  [128, 86]          15,566\n",
      "            Linear-7                  [128, 10]             870\n",
      "================================================================\n",
      "Total params: 9,516,488\n",
      "Trainable params: 9,516,488\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 10.60\n",
      "Params size (MB): 36.30\n",
      "Estimated Total Size (MB): 47.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(DeepFC_net128, input_size=(1, 28, 28), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9t36x7bwgoT",
    "outputId": "859b8789-74c1-4cc7-9af5-f7448fab57d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = images64.to(device)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFHweMakwgoT",
    "outputId": "0dd973cf-2d9d-48c0-ea48-5b5c22920fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = DeepFC_net64.forward(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 5, 30, 30]              50\n",
      "            Conv2d-2            [64, 7, 15, 15]             322\n",
      "            Linear-3                 [64, 3000]       4,728,000\n",
      "            Linear-4                 [64, 1500]       4,501,500\n",
      "            Linear-5                  [64, 180]         270,180\n",
      "            Linear-6                   [64, 86]          15,566\n",
      "            Linear-7                   [64, 10]             870\n",
      "================================================================\n",
      "Total params: 9,516,488\n",
      "Trainable params: 9,516,488\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 5.30\n",
      "Params size (MB): 36.30\n",
      "Estimated Total Size (MB): 41.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(DeepFC_net64, input_size=(1, 28, 28), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klpXGc2tCimP"
   },
   "source": [
    "## 손실함수와 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "69AHX-ZXClOm"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizerDC_128 = optim.SGD(DeepConv_net128.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerDC_64 = optim.SGD(DeepConv_net64.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerFC_128 = optim.SGD(DeepFC_net128.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerFC_64 = optim.SGD(DeepFC_net64.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huNh3EnhJLyh"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-2Q7c6-JW9z"
   },
   "source": [
    "### 1. DeepConv_net128\n",
    "* 10개의 Convolution-layer & 2개의 fc-layer\n",
    "* 128 batch-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-_UvdNWJR-r",
    "outputId": "68ec6932-dafb-4f13-c578-65fa97efe3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.1152688274383545\n",
      "Epoch: 1, Iter: 200, Loss: 0.11520535397529602\n",
      "Epoch: 1, Iter: 300, Loss: 0.11520744931697846\n",
      "Epoch: 1, Iter: 400, Loss: 0.11515410161018372\n",
      "Epoch: 2, Iter: 100, Loss: 0.11514115512371063\n",
      "Epoch: 2, Iter: 200, Loss: 0.11514145529270173\n",
      "Epoch: 2, Iter: 300, Loss: 0.11514410889148712\n",
      "Epoch: 2, Iter: 400, Loss: 0.11513664722442626\n",
      "Epoch: 3, Iter: 100, Loss: 0.11513255298137665\n",
      "Epoch: 3, Iter: 200, Loss: 0.11513179445266723\n",
      "Epoch: 3, Iter: 300, Loss: 0.1151344496011734\n",
      "Epoch: 3, Iter: 400, Loss: 0.11513296186923981\n",
      "Epoch: 4, Iter: 100, Loss: 0.11513360381126404\n",
      "Epoch: 4, Iter: 200, Loss: 0.1151307933330536\n",
      "Epoch: 4, Iter: 300, Loss: 0.11513440537452697\n",
      "Epoch: 4, Iter: 400, Loss: 0.11513096439838409\n",
      "Epoch: 5, Iter: 100, Loss: 0.11512870192527772\n",
      "Epoch: 5, Iter: 200, Loss: 0.11513318681716919\n",
      "Epoch: 5, Iter: 300, Loss: 0.11513384938240051\n",
      "Epoch: 5, Iter: 400, Loss: 0.1151337662935257\n",
      "Epoch: 6, Iter: 100, Loss: 0.11512994420528412\n",
      "Epoch: 6, Iter: 200, Loss: 0.11513079690933227\n",
      "Epoch: 6, Iter: 300, Loss: 0.1151305388212204\n",
      "Epoch: 6, Iter: 400, Loss: 0.11513596343994141\n",
      "Epoch: 7, Iter: 100, Loss: 0.11512861287593841\n",
      "Epoch: 7, Iter: 200, Loss: 0.11512963461875915\n",
      "Epoch: 7, Iter: 300, Loss: 0.11513639533519746\n",
      "Epoch: 7, Iter: 400, Loss: 0.11513209939002991\n",
      "Epoch: 8, Iter: 100, Loss: 0.11513164913654328\n",
      "Epoch: 8, Iter: 200, Loss: 0.11512914335727692\n",
      "Epoch: 8, Iter: 300, Loss: 0.1151335802078247\n",
      "Epoch: 8, Iter: 400, Loss: 0.11513583219051361\n",
      "Epoch: 9, Iter: 100, Loss: 0.11513108944892883\n",
      "Epoch: 9, Iter: 200, Loss: 0.11513120234012604\n",
      "Epoch: 9, Iter: 300, Loss: 0.11513318133354188\n",
      "Epoch: 9, Iter: 400, Loss: 0.11513164222240448\n",
      "Epoch: 10, Iter: 100, Loss: 0.11512685322761536\n",
      "Epoch: 10, Iter: 200, Loss: 0.11513285231590271\n",
      "Epoch: 10, Iter: 300, Loss: 0.11513599824905396\n",
      "Epoch: 10, Iter: 400, Loss: 0.11513352799415588\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizerDC_128.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = DeepConv_net128(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizerDC_128.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNa8-7SC5u2a",
    "outputId": "4c798e1c-af69-46e8-dfb6-7fe3c4cf8020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.1151313818693161\n",
      "Epoch: 1, Iter: 200, Loss: 0.11513164615631104\n",
      "Epoch: 1, Iter: 300, Loss: 0.11513169753551483\n",
      "Epoch: 1, Iter: 400, Loss: 0.11513424623012543\n",
      "Epoch: 2, Iter: 100, Loss: 0.11512998962402343\n",
      "Epoch: 2, Iter: 200, Loss: 0.11513407552242279\n",
      "Epoch: 2, Iter: 300, Loss: 0.11512950468063354\n",
      "Epoch: 2, Iter: 400, Loss: 0.11513549792766571\n",
      "Epoch: 3, Iter: 100, Loss: 0.11513231313228607\n",
      "Epoch: 3, Iter: 200, Loss: 0.1151308991909027\n",
      "Epoch: 3, Iter: 300, Loss: 0.11512910008430481\n",
      "Epoch: 3, Iter: 400, Loss: 0.1151350861787796\n",
      "Epoch: 4, Iter: 100, Loss: 0.11513047051429749\n",
      "Epoch: 4, Iter: 200, Loss: 0.11513212776184081\n",
      "Epoch: 4, Iter: 300, Loss: 0.11513186275959014\n",
      "Epoch: 4, Iter: 400, Loss: 0.11513362383842468\n",
      "Epoch: 5, Iter: 100, Loss: 0.11513021838665008\n",
      "Epoch: 5, Iter: 200, Loss: 0.11513103890419006\n",
      "Epoch: 5, Iter: 300, Loss: 0.11513267910480499\n",
      "Epoch: 5, Iter: 400, Loss: 0.11513408267498017\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizerDC_128.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = DeepConv_net128(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizerDC_128.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOUBE2UfKS6D"
   },
   "source": [
    "### 2. DeepConv_net64\n",
    "* 10개의 Convolution-layer & 2개의 fc-layer\n",
    "* 64 batch-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1znQlsWKS6D",
    "outputId": "fd74107b-a0ea-4917-f9a6-87826edfac96",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11519631624221802\n",
      "Epoch: 1, Iter: 200, Loss: 0.11520696663856507\n",
      "Epoch: 1, Iter: 300, Loss: 0.115200545668602\n",
      "Epoch: 1, Iter: 400, Loss: 0.11516034722328186\n",
      "Epoch: 1, Iter: 500, Loss: 0.11515818786621093\n",
      "Epoch: 1, Iter: 600, Loss: 0.11514895236492156\n",
      "Epoch: 1, Iter: 700, Loss: 0.1151490091085434\n",
      "Epoch: 1, Iter: 800, Loss: 0.11514998531341553\n",
      "Epoch: 1, Iter: 900, Loss: 0.11514566218852997\n",
      "Epoch: 2, Iter: 100, Loss: 0.11511870396137237\n",
      "Epoch: 2, Iter: 200, Loss: 0.11512321186065674\n",
      "Epoch: 2, Iter: 300, Loss: 0.11514762258529664\n",
      "Epoch: 2, Iter: 400, Loss: 0.1151340891122818\n",
      "Epoch: 2, Iter: 500, Loss: 0.11514163160324097\n",
      "Epoch: 2, Iter: 600, Loss: 0.11513954293727875\n",
      "Epoch: 2, Iter: 700, Loss: 0.11513663983345032\n",
      "Epoch: 2, Iter: 800, Loss: 0.115134526014328\n",
      "Epoch: 2, Iter: 900, Loss: 0.11513565623760223\n",
      "Epoch: 3, Iter: 100, Loss: 0.11513239634037017\n",
      "Epoch: 3, Iter: 200, Loss: 0.11513389647006989\n",
      "Epoch: 3, Iter: 300, Loss: 0.11513294553756714\n",
      "Epoch: 3, Iter: 400, Loss: 0.11513843774795532\n",
      "Epoch: 3, Iter: 500, Loss: 0.11513625848293305\n",
      "Epoch: 3, Iter: 600, Loss: 0.11513159894943237\n",
      "Epoch: 3, Iter: 700, Loss: 0.1151328809261322\n",
      "Epoch: 3, Iter: 800, Loss: 0.11514043653011322\n",
      "Epoch: 3, Iter: 900, Loss: 0.11513675940036773\n",
      "Epoch: 4, Iter: 100, Loss: 0.11512819421291351\n",
      "Epoch: 4, Iter: 200, Loss: 0.11513904178142548\n",
      "Epoch: 4, Iter: 300, Loss: 0.11513535213470459\n",
      "Epoch: 4, Iter: 400, Loss: 0.11513326048851014\n",
      "Epoch: 4, Iter: 500, Loss: 0.11513703787326812\n",
      "Epoch: 4, Iter: 600, Loss: 0.11513646018505097\n",
      "Epoch: 4, Iter: 700, Loss: 0.11514119791984558\n",
      "Epoch: 4, Iter: 800, Loss: 0.11513583111763001\n",
      "Epoch: 4, Iter: 900, Loss: 0.1151332219839096\n",
      "Epoch: 5, Iter: 100, Loss: 0.11513413238525391\n",
      "Epoch: 5, Iter: 200, Loss: 0.11512937796115875\n",
      "Epoch: 5, Iter: 300, Loss: 0.1151272873878479\n",
      "Epoch: 5, Iter: 400, Loss: 0.11513707053661347\n",
      "Epoch: 5, Iter: 500, Loss: 0.11514197063446045\n",
      "Epoch: 5, Iter: 600, Loss: 0.11513734018802643\n",
      "Epoch: 5, Iter: 700, Loss: 0.11514015448093415\n",
      "Epoch: 5, Iter: 800, Loss: 0.11513288223743438\n",
      "Epoch: 5, Iter: 900, Loss: 0.11513296222686767\n",
      "Epoch: 6, Iter: 100, Loss: 0.11512837028503418\n",
      "Epoch: 6, Iter: 200, Loss: 0.11512400424480439\n",
      "Epoch: 6, Iter: 300, Loss: 0.11514325284957885\n",
      "Epoch: 6, Iter: 400, Loss: 0.115131174325943\n",
      "Epoch: 6, Iter: 500, Loss: 0.11514055633544922\n",
      "Epoch: 6, Iter: 600, Loss: 0.11513847756385803\n",
      "Epoch: 6, Iter: 700, Loss: 0.11513724303245544\n",
      "Epoch: 6, Iter: 800, Loss: 0.11513520932197571\n",
      "Epoch: 6, Iter: 900, Loss: 0.11513591039180755\n",
      "Epoch: 7, Iter: 100, Loss: 0.11512531983852387\n",
      "Epoch: 7, Iter: 200, Loss: 0.11513926255702972\n",
      "Epoch: 7, Iter: 300, Loss: 0.11513200664520264\n",
      "Epoch: 7, Iter: 400, Loss: 0.1151417337656021\n",
      "Epoch: 7, Iter: 500, Loss: 0.11513208603858947\n",
      "Epoch: 7, Iter: 600, Loss: 0.11513604998588561\n",
      "Epoch: 7, Iter: 700, Loss: 0.11513278234004974\n",
      "Epoch: 7, Iter: 800, Loss: 0.11514414060115814\n",
      "Epoch: 7, Iter: 900, Loss: 0.11513856112957001\n",
      "Epoch: 8, Iter: 100, Loss: 0.11512918388843536\n",
      "Epoch: 8, Iter: 200, Loss: 0.11512980556488037\n",
      "Epoch: 8, Iter: 300, Loss: 0.1151272658109665\n",
      "Epoch: 8, Iter: 400, Loss: 0.11514684283733367\n",
      "Epoch: 8, Iter: 500, Loss: 0.11513418221473694\n",
      "Epoch: 8, Iter: 600, Loss: 0.11513569605350495\n",
      "Epoch: 8, Iter: 700, Loss: 0.11513323056697845\n",
      "Epoch: 8, Iter: 800, Loss: 0.11514204108715058\n",
      "Epoch: 8, Iter: 900, Loss: 0.1151355048418045\n",
      "Epoch: 9, Iter: 100, Loss: 0.11512952816486359\n",
      "Epoch: 9, Iter: 200, Loss: 0.11513339269161224\n",
      "Epoch: 9, Iter: 300, Loss: 0.11514627754688263\n",
      "Epoch: 9, Iter: 400, Loss: 0.11513462030887604\n",
      "Epoch: 9, Iter: 500, Loss: 0.11513857889175415\n",
      "Epoch: 9, Iter: 600, Loss: 0.11512770116329193\n",
      "Epoch: 9, Iter: 700, Loss: 0.11513334465026856\n",
      "Epoch: 9, Iter: 800, Loss: 0.1151448940038681\n",
      "Epoch: 9, Iter: 900, Loss: 0.11513586759567261\n",
      "Epoch: 10, Iter: 100, Loss: 0.11513362050056458\n",
      "Epoch: 10, Iter: 200, Loss: 0.11513106274604798\n",
      "Epoch: 10, Iter: 300, Loss: 0.11513514232635498\n",
      "Epoch: 10, Iter: 400, Loss: 0.11513433802127838\n",
      "Epoch: 10, Iter: 500, Loss: 0.1151412570476532\n",
      "Epoch: 10, Iter: 600, Loss: 0.11513585126399994\n",
      "Epoch: 10, Iter: 700, Loss: 0.11513710081577301\n",
      "Epoch: 10, Iter: 800, Loss: 0.11513540482521058\n",
      "Epoch: 10, Iter: 900, Loss: 0.11513386237621308\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader64, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizerDC_64.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = DeepConv_net64(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizerDC_64.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=64\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaVvtEOvKUgJ"
   },
   "source": [
    "### 3. DeepFC_net128\n",
    "* 2개의 Convolution-layer & 5개의 fc-layer\n",
    "* 128 batch-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "Dwh9TK_1KUgK",
    "outputId": "4e6130c2-f6c4-4046-eb67-e0a2c108182a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11514709734916687\n",
      "Epoch: 1, Iter: 200, Loss: 0.11508109760284424\n",
      "Epoch: 1, Iter: 300, Loss: 0.11496948599815368\n",
      "Epoch: 1, Iter: 400, Loss: 0.11485475850105285\n",
      "Epoch: 2, Iter: 100, Loss: 0.11452050757408141\n",
      "Epoch: 2, Iter: 200, Loss: 0.11414225661754608\n",
      "Epoch: 2, Iter: 300, Loss: 0.11324659860134124\n",
      "Epoch: 2, Iter: 400, Loss: 0.11013254535198212\n",
      "Epoch: 3, Iter: 100, Loss: 0.06706969740986823\n",
      "Epoch: 3, Iter: 200, Loss: 0.04814588910341263\n",
      "Epoch: 3, Iter: 300, Loss: 0.04146896255016327\n",
      "Epoch: 3, Iter: 400, Loss: 0.038058390021324155\n",
      "Epoch: 4, Iter: 100, Loss: 0.0343295156955719\n",
      "Epoch: 4, Iter: 200, Loss: 0.033118194952607156\n",
      "Epoch: 4, Iter: 300, Loss: 0.03217857317626476\n",
      "Epoch: 4, Iter: 400, Loss: 0.03142629465460777\n",
      "Epoch: 5, Iter: 100, Loss: 0.030137917056679727\n",
      "Epoch: 5, Iter: 200, Loss: 0.029816011011600495\n",
      "Epoch: 5, Iter: 300, Loss: 0.028717568546533585\n",
      "Epoch: 5, Iter: 400, Loss: 0.02896797087788582\n",
      "Epoch: 6, Iter: 100, Loss: 0.02776730379462242\n",
      "Epoch: 6, Iter: 200, Loss: 0.027676789775490762\n",
      "Epoch: 6, Iter: 300, Loss: 0.0266092888712883\n",
      "Epoch: 6, Iter: 400, Loss: 0.026278866901993752\n",
      "Epoch: 7, Iter: 100, Loss: 0.025517084062099456\n",
      "Epoch: 7, Iter: 200, Loss: 0.025726231053471566\n",
      "Epoch: 7, Iter: 300, Loss: 0.025202277615666388\n",
      "Epoch: 7, Iter: 400, Loss: 0.024849091917276384\n",
      "Epoch: 8, Iter: 100, Loss: 0.02469045275449753\n",
      "Epoch: 8, Iter: 200, Loss: 0.02397117531299591\n",
      "Epoch: 8, Iter: 300, Loss: 0.023516608461737632\n",
      "Epoch: 8, Iter: 400, Loss: 0.022845347464084627\n",
      "Epoch: 9, Iter: 100, Loss: 0.02301769268512726\n",
      "Epoch: 9, Iter: 200, Loss: 0.022385583132505417\n",
      "Epoch: 9, Iter: 300, Loss: 0.02225378778576851\n",
      "Epoch: 9, Iter: 400, Loss: 0.02206553250551224\n",
      "Epoch: 10, Iter: 100, Loss: 0.021914426177740098\n",
      "Epoch: 10, Iter: 200, Loss: 0.021728061974048616\n",
      "Epoch: 10, Iter: 300, Loss: 0.02176863941550255\n",
      "Epoch: 10, Iter: 400, Loss: 0.021550668522715567\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizerFC_128.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = DeepFC_net128(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizerFC_128.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRyyw49jKVhj"
   },
   "source": [
    "### 4. DeepFC_net128\n",
    "* 2개의 Convolution-layer & 5개의 fc-layer\n",
    "* 64 batch-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X3847V0dKVhk",
    "outputId": "af5186f4-ca85-4423-b6eb-4242c17b7992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11517442405223846\n",
      "Epoch: 1, Iter: 200, Loss: 0.11515807509422302\n",
      "Epoch: 1, Iter: 300, Loss: 0.11506833148002625\n",
      "Epoch: 1, Iter: 400, Loss: 0.11495304548740387\n",
      "Epoch: 1, Iter: 500, Loss: 0.11479924869537353\n",
      "Epoch: 1, Iter: 600, Loss: 0.11463242411613464\n",
      "Epoch: 1, Iter: 700, Loss: 0.11438305795192719\n",
      "Epoch: 1, Iter: 800, Loss: 0.11394029080867768\n",
      "Epoch: 1, Iter: 900, Loss: 0.11313133072853089\n",
      "Epoch: 2, Iter: 100, Loss: 0.10931733095645904\n",
      "Epoch: 2, Iter: 200, Loss: 0.09497743499279022\n",
      "Epoch: 2, Iter: 300, Loss: 0.06888102704286575\n",
      "Epoch: 2, Iter: 400, Loss: 0.05325059509277344\n",
      "Epoch: 2, Iter: 500, Loss: 0.04992942497134209\n",
      "Epoch: 2, Iter: 600, Loss: 0.04636180844902992\n",
      "Epoch: 2, Iter: 700, Loss: 0.04345378479361534\n",
      "Epoch: 2, Iter: 800, Loss: 0.042456513315439225\n",
      "Epoch: 2, Iter: 900, Loss: 0.039675506234169\n",
      "Epoch: 3, Iter: 100, Loss: 0.03720796464383602\n",
      "Epoch: 3, Iter: 200, Loss: 0.03563355831801891\n",
      "Epoch: 3, Iter: 300, Loss: 0.034571101412177084\n",
      "Epoch: 3, Iter: 400, Loss: 0.03297156776487827\n",
      "Epoch: 3, Iter: 500, Loss: 0.032214454784989355\n",
      "Epoch: 3, Iter: 600, Loss: 0.03305758248269558\n",
      "Epoch: 3, Iter: 700, Loss: 0.03219476832449436\n",
      "Epoch: 3, Iter: 800, Loss: 0.03171140110492706\n",
      "Epoch: 3, Iter: 900, Loss: 0.03025753200054169\n",
      "Epoch: 4, Iter: 100, Loss: 0.028885047450661658\n",
      "Epoch: 4, Iter: 200, Loss: 0.029811440661549567\n",
      "Epoch: 4, Iter: 300, Loss: 0.028620587483048437\n",
      "Epoch: 4, Iter: 400, Loss: 0.02790243299305439\n",
      "Epoch: 4, Iter: 500, Loss: 0.027755820721387863\n",
      "Epoch: 4, Iter: 600, Loss: 0.027283629387617112\n",
      "Epoch: 4, Iter: 700, Loss: 0.027369444891810417\n",
      "Epoch: 4, Iter: 800, Loss: 0.02671594136953354\n",
      "Epoch: 4, Iter: 900, Loss: 0.027328533574938776\n",
      "Epoch: 5, Iter: 100, Loss: 0.025535404816269876\n",
      "Epoch: 5, Iter: 200, Loss: 0.024531580373644828\n",
      "Epoch: 5, Iter: 300, Loss: 0.025160196438431738\n",
      "Epoch: 5, Iter: 400, Loss: 0.024668243110179903\n",
      "Epoch: 5, Iter: 500, Loss: 0.024371900767087937\n",
      "Epoch: 5, Iter: 600, Loss: 0.023071598269045354\n",
      "Epoch: 5, Iter: 700, Loss: 0.0242443805038929\n",
      "Epoch: 5, Iter: 800, Loss: 0.022956777393817903\n",
      "Epoch: 5, Iter: 900, Loss: 0.023097177751362323\n",
      "Epoch: 6, Iter: 100, Loss: 0.021642799273133277\n",
      "Epoch: 6, Iter: 200, Loss: 0.02272929013520479\n",
      "Epoch: 6, Iter: 300, Loss: 0.022306728214025497\n",
      "Epoch: 6, Iter: 400, Loss: 0.022045137956738473\n",
      "Epoch: 6, Iter: 500, Loss: 0.022859841510653497\n",
      "Epoch: 6, Iter: 600, Loss: 0.021046637393534184\n",
      "Epoch: 6, Iter: 700, Loss: 0.02112141901254654\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader64, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizerFC_64.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = DeepFC_net64(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizerFC_64.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=64\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IecfHZiI09W"
   },
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjVs_iS0rlof",
    "outputId": "af02f140-f192-4b0b-f026-db763706257f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepConv_net128 : 0.1\n",
      "DeepConv_net64 : 0.1\n",
      "DeepFC_net128 : 0.865\n",
      "DeepFC_net64 : 0.8519\n"
     ]
    }
   ],
   "source": [
    "# 전체 test 데이터에 대해서 성능 확인\n",
    "\n",
    "correct_list = [0]*4\n",
    "total_list = [0]*4\n",
    "a = -1\n",
    "\n",
    "model_list = {'DeepConv' : [DeepConv_net128, DeepConv_net64],\n",
    "              'DeepFC' : [DeepFC_net128, DeepFC_net64]}\n",
    "data_list = [test_loader128, test_loader64]\n",
    "\n",
    "with torch.no_grad(): # grad가 필요없다.\n",
    "\n",
    "    for key in model_list:\n",
    "        for idx in range(len(model_list[key])):\n",
    "            a += 1\n",
    "            model = model_list[key][idx]\n",
    "            data_loader = data_list[idx]\n",
    "            for data in data_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total_list[a] += labels.size(0)\n",
    "                correct_list[a] += (predicted == labels).sum().item()\n",
    "            \n",
    "correct_rate = np.array(correct_list) / np.array(total_list)\n",
    "model_name = ['DeepConv_net128', 'DeepConv_net64', 'DeepFC_net128', 'DeepFC_net64']\n",
    "\n",
    "for i in range(len(correct_rate)):\n",
    "    print('{0} : {1}'.format(model_name[i], correct_rate[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZcZQv4PGeYv"
   },
   "source": [
    "# FashionMNIST 분류 모델 중 성능이 낮은 모델 이유 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7HoLqroDhyF"
   },
   "source": [
    "## Convolution-layer를 하나씩 추가하면서, 성능변화를 관찰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_civVcIYBGxA"
   },
   "source": [
    "### 3개의 convolution-layer 사용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "id": "29zvOdhT-fwY"
   },
   "outputs": [],
   "source": [
    "class CNN_Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(5, 7, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(7, 16, 2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(16* 16 * 16, 3000)\n",
    "        self.fc2 = nn.Linear(3000, 1500)\n",
    "        self.fc3 = nn.Linear(1500, 20 * 3 * 3)\n",
    "        self.fc4 = nn.Linear(20 * 3 * 3, 86)\n",
    "        self.fc5 = nn.Linear(86, 10) # 10 : 10개의 category\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x)) # num_flat_features : 아래에서 정의\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x): # 처음 dim-size을 제외하고, 모두 곱한 값을 반환해준다.\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t81gXZmz-fwY",
    "outputId": "7fe5d139-bf73-43af-e6bc-263471b5f005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model3(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(7, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=4096, out_features=3000, bias=True)\n",
      "  (fc2): Linear(in_features=3000, out_features=1500, bias=True)\n",
      "  (fc3): Linear(in_features=1500, out_features=180, bias=True)\n",
      "  (fc4): Linear(in_features=180, out_features=86, bias=True)\n",
      "  (fc5): Linear(in_features=86, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "new_model = CNN_Model3().to(device)\n",
    "\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb2EkGUbBnuM",
    "outputId": "5f129f9d-2057-4a09-da82-c81dd10d3e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 5, 30, 30]              50\n",
      "            Conv2d-2           [128, 7, 15, 15]             322\n",
      "            Conv2d-3          [128, 16, 16, 16]             464\n",
      "            Linear-4                [128, 3000]      12,291,000\n",
      "            Linear-5                [128, 1500]       4,501,500\n",
      "            Linear-6                 [128, 180]         270,180\n",
      "            Linear-7                  [128, 86]          15,566\n",
      "            Linear-8                  [128, 10]             870\n",
      "================================================================\n",
      "Total params: 17,079,952\n",
      "Trainable params: 17,079,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 14.60\n",
      "Params size (MB): 65.15\n",
      "Estimated Total Size (MB): 80.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(new_model, input_size=(1, 28, 28), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "aQDT4bYIBsZl"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(new_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6GqkR8nBwhH",
    "outputId": "107f1fb2-7ed7-4725-b7b5-ee17a36bad51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11519398355484009\n",
      "Epoch: 1, Iter: 200, Loss: 0.11514422690868378\n",
      "Epoch: 1, Iter: 300, Loss: 0.1151123411655426\n",
      "Epoch: 1, Iter: 400, Loss: 0.11508644258975982\n",
      "Epoch: 2, Iter: 100, Loss: 0.1150071805715561\n",
      "Epoch: 2, Iter: 200, Loss: 0.11495142149925232\n",
      "Epoch: 2, Iter: 300, Loss: 0.11488631844520569\n",
      "Epoch: 2, Iter: 400, Loss: 0.11478898751735687\n",
      "Epoch: 3, Iter: 100, Loss: 0.11438788950443268\n",
      "Epoch: 3, Iter: 200, Loss: 0.11390453338623047\n",
      "Epoch: 3, Iter: 300, Loss: 0.11256192910671234\n",
      "Epoch: 3, Iter: 400, Loss: 0.10448865818977356\n",
      "Epoch: 4, Iter: 100, Loss: 0.04805727195739746\n",
      "Epoch: 4, Iter: 200, Loss: 0.039461121022701266\n",
      "Epoch: 4, Iter: 300, Loss: 0.03552169913053513\n",
      "Epoch: 4, Iter: 400, Loss: 0.03419936951994896\n",
      "Epoch: 5, Iter: 100, Loss: 0.032092437297105786\n",
      "Epoch: 5, Iter: 200, Loss: 0.030611014664173125\n",
      "Epoch: 5, Iter: 300, Loss: 0.030534122958779334\n",
      "Epoch: 5, Iter: 400, Loss: 0.030247083589434624\n",
      "Epoch: 6, Iter: 100, Loss: 0.028526979357004167\n",
      "Epoch: 6, Iter: 200, Loss: 0.02887688048183918\n",
      "Epoch: 6, Iter: 300, Loss: 0.028605852216482163\n",
      "Epoch: 6, Iter: 400, Loss: 0.027949207842350006\n",
      "Epoch: 7, Iter: 100, Loss: 0.02684966030716896\n",
      "Epoch: 7, Iter: 200, Loss: 0.027045142471790313\n",
      "Epoch: 7, Iter: 300, Loss: 0.025665957659482957\n",
      "Epoch: 7, Iter: 400, Loss: 0.02472960416972637\n",
      "Epoch: 8, Iter: 100, Loss: 0.024742569491267203\n",
      "Epoch: 8, Iter: 200, Loss: 0.02464320960640907\n",
      "Epoch: 8, Iter: 300, Loss: 0.02395121328532696\n",
      "Epoch: 8, Iter: 400, Loss: 0.023661399126052855\n",
      "Epoch: 9, Iter: 100, Loss: 0.02410077352821827\n",
      "Epoch: 9, Iter: 200, Loss: 0.023181424871087073\n",
      "Epoch: 9, Iter: 300, Loss: 0.022967235252261162\n",
      "Epoch: 9, Iter: 400, Loss: 0.02262467311322689\n",
      "Epoch: 10, Iter: 100, Loss: 0.02205083529651165\n",
      "Epoch: 10, Iter: 200, Loss: 0.022077771797776223\n",
      "Epoch: 10, Iter: 300, Loss: 0.021797703891992568\n",
      "Epoch: 10, Iter: 400, Loss: 0.021889505565166473\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = new_model(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizer.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PDu2v9bB_NE",
    "outputId": "7ef829e6-4309-4ac6-e21e-e401c94bab72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.61\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader128:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = new_model(images)\n",
    "        _, predicted = torch.max(outputs.data, axis=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Thu9NRyCV7j"
   },
   "source": [
    "### 4개의 convolution-layer 사용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "id": "V9PQvGFPCV7k"
   },
   "outputs": [],
   "source": [
    "class CNN_Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model4, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(5, 7, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(7, 16, 2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 19, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(15* 15 * 19, 3000)\n",
    "        self.fc2 = nn.Linear(3000, 1500)\n",
    "        self.fc3 = nn.Linear(1500, 20 * 3 * 3)\n",
    "        self.fc4 = nn.Linear(20 * 3 * 3, 86)\n",
    "        self.fc5 = nn.Linear(86, 10) # 10 : 10개의 category\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x)) # num_flat_features : 아래에서 정의\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x): # 처음 dim-size을 제외하고, 모두 곱한 값을 반환해준다.\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNAL7SRZCV7k",
    "outputId": "8b307f14-532d-45cd-dd0a-0e164652a287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model3(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(7, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(16, 19, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=4275, out_features=3000, bias=True)\n",
      "  (fc2): Linear(in_features=3000, out_features=1500, bias=True)\n",
      "  (fc3): Linear(in_features=1500, out_features=180, bias=True)\n",
      "  (fc4): Linear(in_features=180, out_features=86, bias=True)\n",
      "  (fc5): Linear(in_features=86, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "new_model = CNN_Model4().to(device)\n",
    "\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHmIarJBCV7k",
    "outputId": "a5f1f957-cdb1-40a9-e2b5-6c94153d474c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 5, 30, 30]              50\n",
      "            Conv2d-2           [128, 7, 15, 15]             322\n",
      "            Conv2d-3          [128, 16, 16, 16]             464\n",
      "            Conv2d-4          [128, 19, 15, 15]           1,235\n",
      "            Linear-5                [128, 3000]      12,828,000\n",
      "            Linear-6                [128, 1500]       4,501,500\n",
      "            Linear-7                 [128, 180]         270,180\n",
      "            Linear-8                  [128, 86]          15,566\n",
      "            Linear-9                  [128, 10]             870\n",
      "================================================================\n",
      "Total params: 17,618,187\n",
      "Trainable params: 17,618,187\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 18.77\n",
      "Params size (MB): 67.21\n",
      "Estimated Total Size (MB): 86.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(new_model, input_size=(1, 28, 28), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "z6gegPTRCV7k"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(new_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeeKVQdKCV7k",
    "outputId": "e419d6a6-8405-4d05-9c6a-d661c0c4b91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11519611871242523\n",
      "Epoch: 1, Iter: 200, Loss: 0.11521574079990388\n",
      "Epoch: 1, Iter: 300, Loss: 0.11521736824512482\n",
      "Epoch: 1, Iter: 400, Loss: 0.11515061974525452\n",
      "Epoch: 2, Iter: 100, Loss: 0.11516089415550232\n",
      "Epoch: 2, Iter: 200, Loss: 0.11512716960906982\n",
      "Epoch: 2, Iter: 300, Loss: 0.11513755357265472\n",
      "Epoch: 2, Iter: 400, Loss: 0.11511598992347717\n",
      "Epoch: 3, Iter: 100, Loss: 0.11513030612468719\n",
      "Epoch: 3, Iter: 200, Loss: 0.11509760749340057\n",
      "Epoch: 3, Iter: 300, Loss: 0.11510218334197998\n",
      "Epoch: 3, Iter: 400, Loss: 0.11510523653030395\n",
      "Epoch: 4, Iter: 100, Loss: 0.11509827101230621\n",
      "Epoch: 4, Iter: 200, Loss: 0.11508925342559814\n",
      "Epoch: 4, Iter: 300, Loss: 0.11509384608268738\n",
      "Epoch: 4, Iter: 400, Loss: 0.11509047281742096\n",
      "Epoch: 5, Iter: 100, Loss: 0.11508220613002777\n",
      "Epoch: 5, Iter: 200, Loss: 0.11507677328586578\n",
      "Epoch: 5, Iter: 300, Loss: 0.11507185316085815\n",
      "Epoch: 5, Iter: 400, Loss: 0.11506561255455017\n",
      "Epoch: 6, Iter: 100, Loss: 0.11505461275577546\n",
      "Epoch: 6, Iter: 200, Loss: 0.11505101835727692\n",
      "Epoch: 6, Iter: 300, Loss: 0.11504114174842835\n",
      "Epoch: 6, Iter: 400, Loss: 0.11503183913230897\n",
      "Epoch: 7, Iter: 100, Loss: 0.11501241183280944\n",
      "Epoch: 7, Iter: 200, Loss: 0.11499932408332825\n",
      "Epoch: 7, Iter: 300, Loss: 0.11498291552066803\n",
      "Epoch: 7, Iter: 400, Loss: 0.11496755599975586\n",
      "Epoch: 8, Iter: 100, Loss: 0.11492174446582794\n",
      "Epoch: 8, Iter: 200, Loss: 0.11488599717617035\n",
      "Epoch: 8, Iter: 300, Loss: 0.11484336411952972\n",
      "Epoch: 8, Iter: 400, Loss: 0.11478675770759582\n",
      "Epoch: 9, Iter: 100, Loss: 0.11462692523002624\n",
      "Epoch: 9, Iter: 200, Loss: 0.11447418415546418\n",
      "Epoch: 9, Iter: 300, Loss: 0.11422021663188935\n",
      "Epoch: 9, Iter: 400, Loss: 0.1137476851940155\n",
      "Epoch: 10, Iter: 100, Loss: 0.11112988305091857\n",
      "Epoch: 10, Iter: 200, Loss: 0.09806095296144486\n",
      "Epoch: 10, Iter: 300, Loss: 0.057501908659935\n",
      "Epoch: 10, Iter: 400, Loss: 0.04588349795341492\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = new_model(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizer.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3uuDeS_CV7k",
    "outputId": "4ecf936e-91d6-4bfc-8546-93801e16d158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.73\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader128:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = new_model(images)\n",
    "        _, predicted = torch.max(outputs.data, axis=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuP_3_DyD42p"
   },
   "source": [
    "### 5개의 convolution-layer 사용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "id": "Bk1u7iloD42q"
   },
   "outputs": [],
   "source": [
    "class CNN_Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(5, 7, 3, padding=1)      \n",
    "        self.conv3 = nn.Conv2d(7, 16, 2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 19, 2)\n",
    "        self.conv5 = nn.Conv2d(19, 29, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(29 * 13 * 13, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 25)\n",
    "        self.fc4 = nn.Linear(25, 10) # 10 : 10개의 category\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x)) # num_flat_features : 아래에서 정의\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x): # 처음 dim-size을 제외하고, 모두 곱한 값을 반환해준다.\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPoNB-4vD42q",
    "outputId": "57c3b06d-6bc0-47f2-8b8d-ea4fb0cbb367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model3(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(7, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(16, 19, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv5): Conv2d(19, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=4901, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (fc4): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "new_model = CNN_Model5().to(device)\n",
    "\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDvnyPw6D42q",
    "outputId": "aca3d67f-32f8-4e13-aca2-fdff8d8ad95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 5, 30, 30]              50\n",
      "            Conv2d-2           [128, 7, 15, 15]             322\n",
      "            Conv2d-3          [128, 16, 16, 16]             464\n",
      "            Conv2d-4          [128, 19, 15, 15]           1,235\n",
      "            Conv2d-5          [128, 29, 13, 13]           4,988\n",
      "            Linear-6                 [128, 100]         490,200\n",
      "            Linear-7                  [128, 50]           5,050\n",
      "            Linear-8                  [128, 25]           1,275\n",
      "            Linear-9                  [128, 10]             260\n",
      "================================================================\n",
      "Total params: 503,844\n",
      "Trainable params: 503,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 19.07\n",
      "Params size (MB): 1.92\n",
      "Estimated Total Size (MB): 21.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(new_model, input_size=(1, 28, 28), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "id": "QmOiVQDLD42q"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(new_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eS9fQfeED42q",
    "outputId": "32596c0d-797c-4de6-9a7b-0dd97ddf891b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss: 0.11543198049068451\n",
      "Epoch: 1, Iter: 200, Loss: 0.11530282306671143\n",
      "Epoch: 1, Iter: 300, Loss: 0.11530901575088501\n",
      "Epoch: 1, Iter: 400, Loss: 0.11522050750255584\n",
      "Epoch: 2, Iter: 100, Loss: 0.11522065305709839\n",
      "Epoch: 2, Iter: 200, Loss: 0.11515305805206298\n",
      "Epoch: 2, Iter: 300, Loss: 0.11515569114685059\n",
      "Epoch: 2, Iter: 400, Loss: 0.11516375982761383\n",
      "Epoch: 3, Iter: 100, Loss: 0.11512697637081146\n",
      "Epoch: 3, Iter: 200, Loss: 0.11513668882846832\n",
      "Epoch: 3, Iter: 300, Loss: 0.11514008140563965\n",
      "Epoch: 3, Iter: 400, Loss: 0.11511781585216523\n",
      "Epoch: 4, Iter: 100, Loss: 0.11511454820632934\n",
      "Epoch: 4, Iter: 200, Loss: 0.11512211894989013\n",
      "Epoch: 4, Iter: 300, Loss: 0.11512244129180908\n",
      "Epoch: 4, Iter: 400, Loss: 0.1151157341003418\n",
      "Epoch: 5, Iter: 100, Loss: 0.11511646783351898\n",
      "Epoch: 5, Iter: 200, Loss: 0.11511037909984588\n",
      "Epoch: 5, Iter: 300, Loss: 0.11511185359954834\n",
      "Epoch: 5, Iter: 400, Loss: 0.115108726978302\n",
      "Epoch: 6, Iter: 100, Loss: 0.1151046621799469\n",
      "Epoch: 6, Iter: 200, Loss: 0.11509593641757965\n",
      "Epoch: 6, Iter: 300, Loss: 0.11510584712028503\n",
      "Epoch: 6, Iter: 400, Loss: 0.11509858441352844\n",
      "Epoch: 7, Iter: 100, Loss: 0.11508784222602844\n",
      "Epoch: 7, Iter: 200, Loss: 0.11509343922138214\n",
      "Epoch: 7, Iter: 300, Loss: 0.11508572506904602\n",
      "Epoch: 7, Iter: 400, Loss: 0.11508496224880219\n",
      "Epoch: 8, Iter: 100, Loss: 0.1150725667476654\n",
      "Epoch: 8, Iter: 200, Loss: 0.11506851267814636\n",
      "Epoch: 8, Iter: 300, Loss: 0.11505920016765595\n",
      "Epoch: 8, Iter: 400, Loss: 0.11505410742759704\n",
      "Epoch: 9, Iter: 100, Loss: 0.11503372168540954\n",
      "Epoch: 9, Iter: 200, Loss: 0.11501808845996857\n",
      "Epoch: 9, Iter: 300, Loss: 0.11501030027866363\n",
      "Epoch: 9, Iter: 400, Loss: 0.11498795902729034\n",
      "Epoch: 10, Iter: 100, Loss: 0.11494731914997101\n",
      "Epoch: 10, Iter: 200, Loss: 0.11491318464279175\n",
      "Epoch: 10, Iter: 300, Loss: 0.11487376725673676\n",
      "Epoch: 10, Iter: 400, Loss: 0.11480642557144165\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader128, start=0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad() # epoch마다 gradient 0으로 초기화\n",
    "\n",
    "        outputs = new_model(inputs) # y_pred = f(X)\n",
    "        loss = criterion(outputs, labels) # CrossEntropyLoss; 0~1 사이값\n",
    "        loss.backward() # back-propagation; gradient 계산\n",
    "        optimizer.step() # parameters(weights) update\n",
    "\n",
    "        running_loss += loss.item() # 그냥 전체적인 비교를 위해 누적함\n",
    "\n",
    "        if i % 100 == 99: # 100번 마다 확인; epoch=10, iter(=i)=469, batch=128\n",
    "            print('Epoch: {}, Iter: {}, Loss: {}'.format(epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0H3p7PGD42q",
    "outputId": "acb56f79-c9dc-40d4-d649-4178b9a1502f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.44\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader128:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = new_model(images)\n",
    "        _, predicted = torch.max(outputs.data, axis=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(100 * correct / total)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cdNvme8aKSBP",
    "OHckdZ55KeH2",
    "mCrBa-gRRMEO",
    "EFPYE3UUnpmX",
    "xVxKI_rwCvhI",
    "klpXGc2tCimP",
    "huNh3EnhJLyh",
    "W-2Q7c6-JW9z",
    "FOUBE2UfKS6D",
    "LaVvtEOvKUgJ",
    "jRyyw49jKVhj",
    "5IecfHZiI09W",
    "SZcZQv4PGeYv",
    "V7HoLqroDhyF",
    "_civVcIYBGxA",
    "7Thu9NRyCV7j",
    "kuP_3_DyD42p"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
